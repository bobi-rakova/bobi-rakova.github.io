<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Bogdana (Bobbi) Rakova</title>
  <meta name="description" content="Bobi Rakova">
  <meta name="author" content="Bobi Rakova">

  <base target="_blank">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Kelly - v4.3.0
  * Template URL: https://bootstrapmade.com/kelly-free-bootstrap-cv-resume-html-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container-fluid d-flex justify-content-between align-items-center">

      <h1 class="logo me-auto me-lg-0"><a href="index.html">Bogdana Rakova</a></h1>
      <!-- Uncomment below if you prefer to use an image logo -->
      <!-- <a href="index.html" class="logo"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->

      <nav id="navbar" class="navbar order-last order-lg-0">
        <ul>
          <li><a class="active" href="index.html">About</a></li>
          <li><a href="resume.html" target="_self">Research</a></li>
          <li><a href="work.html" target="_self">Projects</a></li>
          <li><a href="https://bobi-rakova.medium.com/">Blog</a></li>
          <li><a href="cv_BogdanaRakova.pdf">CV</a></li>
          <li><a href="mailto:b.rakova@gmail.com">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

      <div class="header-social-links">
        <a href="https://twitter.com/bobirakova" class="twitter"><i class="bi bi-twitter"></i></a>
        <a href="https://www.linkedin.com/in/bogdanarakova/" class="linkedin"><i class="bi bi-linkedin"></i></i></a>
      </div>

    </div>

  </header><!-- End Header -->

  <!-- ======= Hero Section ======= -->
  <section class="align-items-center">
    <div class="container d-flex flex-column align-items-center" data-aos="zoom-in" data-aos-delay="100">
      <br />
      <br />

      <div class="row">

        <div class="row" style="margin-top: 15px;">
          <div class="col-lg-4">
            <img class="img-fluid" alt="" src="http://bobirakova.com/images/workshop_headshot_small.jpg"> </img>
          </div>

          <div class="col-md-8">
            <h3>Building Agentic AI Systems Evaluation Pipelines through Legal Red-Teaming, Standardization, and Mechanism Design</h3>
            <p> 
              <!-- I started out as a Computer Scientist, Machine Learning engineer, and researcher, now doing work at the intersection with Science and Technology Studies and Computational Law.   -->
            

            Bogdana (Bobbi) is a senior data scientist at the global <b>Responsible AI team at DLA Piper,</b> where her work is focused on legal red-teaming and safety guardrails. Her research centers algorithmic impact assessments, participatory mechanism design, legal innovation, and the use of speculative methods to explore a wide range of possible futures. She is also a <b>Data & Society Institute</b> affiliate and has a passion for empowering people to trust AI systems through actionable models of evaluation and engagement in the AI lifecycle, centered on equity, access, and justice.

            Previously, a senior trustworthy AI fellow at the <b>Mozilla Foundation (2022-24)</b>, working on <a href="https://bobi-rakova.medium.com/reimagining-consent-and-contestability-in-ai-56979a88a7fb">reimagining consent and contestability in AI</a>. A research manager at the <a href="https://www.accenture.com/us-en/insights/artificial-intelligence/responsible-ai-principles-practice">Responsible AI team at Accenture</a> where she worked on bringing the latest research on AI impact assessments into practice for diverse clients.
               
                Bobbi is a lead guest editor of the Springer journal  Special Issue: <a href="https://link.springer.com/journal/42413/volumes-and-issues/3-4">Intersections of Artificial Intelligence and Community Well-Being</a>.
                As a research fellow at <a href="https://www.partnershiponai.org/challenges-for-responsible-ai-practitioners/">Partnership on AI</a>, she worked on disentangling the intersection of organizational structure and the work within the growing field of Responsible AI.

                Bobbi is passionate about the intersection of AI, community well-being, and environmental regeneration, also as part of the <a href="https://www.happycounts.org/">Happiness Alliance</a>.
                She was part of the core team who brought together the <a href="https://beyondstandards.ieee.org/ieee-7010-2020-launch-prioritizes-human-well-being-and-environmental-sustainability-via-technology/"> IEEE 7010-2020 Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-Being</a>. Prior to that she was a senior machine learning research engineer at <a href="https://thinktankteam.info/">Samsung's innovation Think Tank Team</a> where she worked on novel human-computer interaction interfaces, resulting in four patents. Previously, in 2013 she co-founded a company at the intersection of AI and workforce automation.
            </p>
          </div>
        </div>
        </div>
      <!-- <a href="mailto:b.rakova@gmail.com" class="btn-about">Say Hello</a> -->
    </div>
  </section><!-- End Hero -->



  <!-- ======= MAIN CONTENT Section ======= -->
  <section id="resume" class="resume">

    <!------- RECENT UPDATES ------>
    <div class="container" data-aos="fade-up">

      <div class="section-title">
        <h2>Recent updates</h2>
      </div>


      <div class="row">
        <div class="resume-item">
            <h5>workshop / April 3-4th, 2024</h5> <a href="https://rebootingsocialmedia.org/events/trust-safety-in-the-majority-world-workshop/">Trust & Safety in the Majority World</a> - I'm leading a session on AI Systems & Model Development for Majority World Countries during a workshop co-organized by Institute for Rebooting Social Media, Berkman Klein Center for Internet and Society, and the Integrity Institute. 
        </div> 
        <div class="resume-item">
            <h5>workshop / March 22, 2024</h5> <a href="https://speculativefriction.org/communitycall">Speculative Friction Community Call</a> - Friction between lived experiences, incentive structures, and power dynamics in the data and AI ecosystem makes it challenging for individuals and communities to negotiate for their digital sovereignty and rights. How do we eliminate "bad" friction and build in "good" friction that creates space for constructive dialogue, understanding, transparency, learning, and care, in the context of generative AI adoption within specific domains? Who gets to decide what is "good" and "bad" friction and how is this related to design choices such as seams, explainability, human-centered design, and human agency, as well as algorithmic auditing, evaluation, and improving safety for algorithmic systems?
        </div> 
        <div class="resume-item">
            <h5>article / Feb. 28, 2024</h5> <a href="https://foundation.mozilla.org/en/blog/evaluating-llms-through-a-federated-scenario-writing-approach/">Evaluating LLMs Through a Federated, Scenario-Writing Approach</a> - I share the outcomes of a 4-month collaboration sprint in partnership with LLM startup <a href="https://kwanelesouthafrica.org/">Kwanele South Africa</a> and Meg Young and Tamara Kneese from <a href="https://datasociety.net/algorithmic-impact-methods-lab/">Data & Society Research Institute</a>, where we evolve a relational, community-led, participatory, and socio-technical approach to the evaluation of emerging generative AI applications.
        </div> 
        <div class="resume-item">
            <h5>article / Feb. 16, 2024 </h5> <a href="https://foundation.mozilla.org/en/blog/building-positive-futures-for-generative-ai-adoption-in-healthcare/">Building Positive Futures for Generative AI Adoption in Healthcare</a> - learnings from the <a href="https://speculativefriction.org/events">Speculative F(r)iction in Generative AI</a> event I organized where we imagined and experienced a possible future world where every AI agent must have a social license to operate. During the workshop, 79 participants discussed scenarios for using a social license when an AI agent is introduced in patient-clinician interactions in healthcare. The article provides an overview of the state-of-the-art research on introducing generative AI in a healthcare setting. Then I provide perspectives from the public through the lens of the workshop participants and experts I’ve interviewed, including clinicians piloting AI tools in their practice.
        </div>       
        <div class="resume-item">
            <h5>article</h5> <a href="https://bobi-rakova.medium.com/trustworthy-ai-futures-reflections-from-being-a-mozilla-fellow-in-2023-78d7df6cd11b">Trustworthy AI futures: reflections from being a Mozilla Fellow in 2023</a> - the global Mozilla ecosystem, rapid socio-technical prototyping, building alternatives to the status quo, building incentive structures, and multi-stakeholder engagement.
        </div>
        <div class="resume-item">
            <h5>article</h5> <a href="https://foundation.mozilla.org/en/blog/engaging-on-responsible-ai-terms-rewriting-the-small-print-of-everyday-ai-systems/">Engaging on Responsible AI Terms: Rewriting the Small Print of Everyday AI Systems</a> - (1) contextual disclosure of data and AI governance, (2) contestability mechanisms and third-party oversight in incident reporting, and (3) engagement and active co-design of user agreements.
        </div>
        <div class="resume-item">
          <h5>paper</h5> [ACM FAccT Conference, 2023] <a href="https://arxiv.org/pdf/2305.05733.pdf">Algorithms as Social-Ecological-Technological Systems: an Environmental Justice lens on Algorithmic Audits</a> - in collaboration with Roel Dobbe, Assistant Professor - Technology, Policy & Management at Delft University of Technology. Read a summary blog post <a href="https://montrealethics.ai/algorithms-as-social-ecological-technological-systems-an-environmental-justice-lens-on-algorithmic-audits/">here</a>. 
        </div>
        <div class="resume-item">
          <h5>paper</h5> [Big Data & Society, 2023] <a href="https://journals.sagepub.com/doi/10.1177/20539517231211553">Terms-we-serve-with: Five dimensions for anticipating and repairing algorithmic harm</a> in collaboration with Dr. Renee Shelby and Dr. Megan Ma.
          </div>
          <div class="resume-item">
            <h5>October 19</h5> Join me at the Greenlining Institute’s <a href="https://greenlining.org/just-future-summit/">Just Futures Summit</a> to learn about my work on Embedding Equity Into AI and Automated Decision Systems.
          </div>
          <div class="resume-item">
            <h5>October 16-17</h5> Join me at the workshop on <a href="https://casmi.northwestern.edu/workshops-events/workshops/">Operationalizing the Measure Function of the NIST AI Risk Management Framework</a>
          </div>
          <div class="resume-item">
            <h5>October 15</h5> Presenting some work at the CSCW (Computer-Supported Cooperative Work And Social Computing) workshop on <a href="https://sites.google.com/umn.edu/epistemic-injustice-cscw2023/home">Epistemic Injustice in Online Communities</a>
          </div>
      </div>
    </div>
    <br />

    <!------- ONGOING PROJECT ------>
    <div class="container" data-aos="fade-up">

      <div class="section-title">
        <h2>Ongoing Projects</h2>
      </div>

      <div class="row">
        <div class="col-lg-4">
          <img class="img-fluid" alt="" src="./images/twsw_small.png"> </img> <br /><br />
          <p>The <a href="https://termsweservewith.org/">Terms-we-Serve-with</a> (TwSw) is a social, computational, and legal design framework. Along each of its five dimensions, we help technology companies, communities, and policymakers <b>co-design and operationalize critical feminist interventions that help them engage with AI in a way centered on trust, transparency, and human agency.</b> <a href="https://docs.google.com/forms/d/e/1FAIpQLSd0cSI7aNkP40uDdEw63tSlhiqHLfdj4cuaS8cg3rkDJ1g3oA/viewform">Express your interest in joining our online focus group here.</a> </p>
        </div>

        <div class="col-lg-4">

          <img class="img-fluid" alt="" src="./images/project_env.jpg"> </img> <br /><br />
          <p>The <a href="https://notionforms.io/forms/ecosystemic-ai-working-group-2ttywq">Ecosystemic AI Working Group</a>  is a space for (1) conceptualizing and measuring environmental sustainability and justice dimensions of the material resource flows of AI systems and their computational infrastructure, (2) considerations in the way AI is used in environmental projects, and (3) more radical proposals for how AI could be better aligned with making kin in a more-than-human world.</p>          

        </div>

        <div class="col-lg-4">

          <img class="img-fluid" alt="" src="./images/project_specfri.jpeg"> </img> <br /><br />
          <p>The <a href="https://speculativefriction.org/">Speculative Friction Collaborative Design Library</a> is a space for articulating and negotiating the social, political, and environmental aspects of friction between individuals, communities, and AI systems. It centers the question of - <em>What kinds of constructive f(r)iction could contribute towards improved transparency, evaluation, and human agency in the context of generative AI systems and the data and labor pipelines they depend on? </em>  <a href="https://speculativefriction.org/events">Join the launch event here.</a> </p>

        </div>        
      </div>
      <br /><br />
    </div>

    <div class="container" data-aos="fade-up">

      <div class="section-title">
        <h2>Talks, articles, and competition awards</h2>
      </div>

      <div class="row">
        <div class="col-lg-6">
          <div class="resume-item">
            <h4 class="yellow_highlight_padding">AI Transparency through verification</h4>
            <h5>March, 2022 - ongoing</h5>
            <p>As a <a href="https://foundation.mozilla.org/en/blog/seven-new-senior-fellows-selected-to-help-fuel-the-movement-for-trustworthy-ai/">Senior Trustworthy AI Fellow at Mozilla</a>, I am working on a new project which aims to improve AI transparency through building open-source tools that enable the verification of properties of the outcomes of consumer tech AI systems. It is a socio-technical proposal for <a href="https://foundation.mozilla.org/en/blog/terms-we-serve-with-introducing-a-new-mechanism-for-engaging-with-algorithmic-systems/">a Terms-we-Serve-with social, computational, and legal contract</a> for restructuring power dynamics and information asymmetries between consumers and AI companies. </p>
            <p>Together with Dr. Megan Ma, a CodeX Fellow at the Stanford Law School, we also presented the project at the <a href="https://datasociety.net/announcements/2021/10/28/the-social-life-of-algorithmic-harms/">Data & Society academic workshop on the 'Social Life of Algorithmic Harm'</a></p>
            <!-- <p><b class="yellow_highlight">Get involved</b> in this project though reaching out to me directly or participating at an upcomming workshop <a href="https://docs.google.com/forms/d/e/1FAIpQLSceJ1W6OZCiGI3itg61efpO3kXx0pwTOWEQ5mfq0K6J96Sedg/viewform">here</a>.</p> -->
          </div>
                   
          <div class="resume-item">
            <h4>IEEE Technology and Society Magazine</h4>
            <h5>June, 2021</h5>
            <p><a href="https://ieeexplore.ieee.org/document/9445790?source=authoralert">Explaining the Principles to Practices Gap in AI</a> -
            investigating six potential explanations for the principles-to-practice gap in Responsible AI: 1) a misalignment of incentives; 2) the complexity of AI’s impacts; 3) a disciplinary divide; 4) the organizational distribution of responsibilities; 5) the governance of knowledge; and 6) challenges with identifying best practices.</p>
            <p>We emphasize the AI impact assessment process as one promising strategy, which we discuss in the context of AI used for forest ecosystem restoration.</p>
          </div>
          <div class="resume-item pb-0">
            <h4>Berkeley BIDS Computational Social Science Forum</h4>
            <h5>April 26, 2021</h5>
            <p><a href="https://bids.berkeley.edu/events/css-forum-2021-0426">A Relational View on Ethics and Technology</a>:
              Bringing awareness to our inherent positionality, we gain new perspectives about the relational nature of (un)intended consequences of AI systems.
      Giving examples from a recent ethnographic study in the intersection of Organizational Studies and the work on ensuring the responsible development and use of AI, exploring the so-called socio-technical context - the lived experience of the people actively involved in the AI ethics field.
      Learning from the field of Participatory Relational Design, we investigate what can we learn from the design of social movements (specifically in the Global South) about the way we work to ensure better alignment between AI systems and human and ecological well-being.</p>
          </div>
          <div class="resume-item">
            <h4>AI &amp; Well-being Roundtable</h4>
            <h5>January, 2021</h5>
            <p>Participated at the <a href="https://www.happinessroundtable.org/bogdana-rakova.html">Happiness Alliance roundtable: AI &amp; Well-being</a></p>
          </div>
          <div class="resume-item">
            <h4>Foresight Institute</h4>
            <h5>January, 2021</h5>
            <p>Co-lead a session during the Foresight Institute 2020 AGI Strategy conference - <a href="https://www.youtube.com/watch?v=IQ4rQXfqM8M&ab_channel=ForesightInstitute">Organizing for Beneficial AGI: Lessons From Industry.</a></p>
          </div>
          <div class="resume-item">
            <h4>All Tech is Human</h4>
            <p>Published an article: <a href="https://alltechishuman.org/blog/the-intermingling-between-artificial-intelligence-and-community-well-being-a-few-perspectives-on-the-possibilities">Perspectives on the possibilities in the intersection of AI and Community Well-being.</a></p>
            <p>Featured in the All Tech Is Human <a href="https://www.scribd.com/document/476272088/Guide-to-Responsible-Tech-How-to-Get-Involved-Build-a-Better-Tech-Future">Guide to Responsible Tech: How to Get Involved & Build a Better Tech Future (page 24).</a></p>
            <p>Gave a <a href="https://www.youtube.com/watch?v=hPhJ5SU4Vx4&ab_channel=ThoughtWorks">keynote talk at the All Tech is Human 2019 conference in NY, USA.</a></p>
          </div>
          <div class="resume-item">
            <h4>Nature</h4>
            <h5>October 8, 2019</h5>
            <p>Contributed to <a href="https://www.nature.com/articles/d41586-019-03002-8">Machine behavior is old wine in new bottles</a></p>
          </div>
          <div class="resume-item">
            <h4>Harvard Berkman Klein Center & MIT Media Lab</h4>
            <h5>January - May, 2018</h5>
            <p>I was a mentor at the <a href="https://www.berkmankleinassembly.org/fellowship-2018people">Assembly: Ethics and Governance of AI</a> program led by Professor Jonathan Zittrain and Professor Joi Ito.
              Working closely with the program participants gave me an in-depth understanding of the rising legal, policy, and regulatory considerations of investigating the unintended consequences of AI-driven systems.</p>
          </div>
        </div>
        <div class="col-lg-6">
          <!-- <h3 class="resume-title">Professional Experience</h3> -->
          <div class="resume-item">
            <h4>Sustainability, justice, and socio-ecological dimensions of AI</h4>
            <h5>March, 2022 - ongoing</h5>
            <p>What if we could explore the complex dynamic relationship between technical AI artifacts and environmental ecosystems by <a href="https://branch.climateaction.tech/issues/issue-4/slowing-down-ai-with-speculative-friction/">slowing down AI with speculative friction</a>? To explore this question, I co-organized an interdisciplinary workshop on <a href="https://ecosystemic-ai.github.io/">the (eco)systemic challenges in AI</a> at the Hybrid Human AI Conference in Amsterdam, June 14th 2022. Our goal was to center socio-ecological perspectives in the design, development, and deployment of AI. 
              On March 24th, 2023, I'm hosting a panel discussion at the Mozilla MozFest event <a href="https://aisustainability.cargo.site/">centered on the emergent need to consider the relationship between algorithmic systems, the sustainability of computing infrastructure, and arguments for climate and environmental justice.</a> How do we empower improved transparency about the carbon footprint of AI systems as well as broader sustainability concerns with regards to their downstream impacts on human decision-making, nonhuman life, and ecosystems? For example, consider environmental and climate justice dimensions of the way AI systems are designed, developed, and deployed in the built environment or the way opaque AI systems contribute to climate misinformation.
            </p>
          </div>

          <div class="resume-item">
            <h4>Summary of my work with Partnership on AI</h4>
            <h5>March 8, 2021</h5>
            <p><a href="https://www.partnershiponai.org/challenges-for-responsible-ai-practitioners/">Challenges for Responsible AI Practitioners and the Importance of Solidarity</a> - common obstacles faced by the practitioners we interviewed included lack of accountability, ill-informed performance trade-offs, and misalignment of incentives within decision-making structures. These obstacles can be understood as a result of how organizations answer four key questions: When and how do we act? How do we measure success? What are the internal structures we rely on? And how do we resolve tensions? These are questions that every organization must have a process for answering when developing responsible AI practices. We employed a systems thinking forecasting activity to map the possible paths forward, which we describe in our CSCW publication <a href="https://dl.acm.org/doi/10.1145/3449081">here</a>.
            </p>
          </div>
          <div class="resume-item">
            <h4>Responsible AI: From principles to practice</h4>
            <h5>March, 2021</h5>
            <p>Contributed to global report discussing the <a href="https://www.accenture.com/_acnmedia/PDF-149/Accenture-Responsible-AI-Final.pdf">Responsible AI practice at Accenture.</a></p>
          </div>
          <div class="resume-item">
            <h4>Springer Special Issue Publication</h4>
            <h5>December, 2020</h5>
            <p>I was a lead guest editor for the <a href="https://link.springer.com/journal/42413/volumes-and-issues/3-4">Special Issue: Intersections of Artificial Intelligence and Community Well-Being</a>. The key themes among the contributions to the publication include:</p>
            <ul>
              <li>Understanding and measuring the impact of AI on community well-being.</li>
              <li>Engaging communities in the development and deployment of AI.</li>
              <li>The role of AI systems in the protection of community well-being.</li>
            </ul>
          </div>
          <div class="resume-item">
            <h4>MIT Sloan Management Review</h4>
            <h5>October 22, 2020</h5>
            <p><a href="https://sloanreview.mit.edu/article/putting-responsible-ai-into-practice/">Putting Responsible AI Into Practice:</a> A survey of individuals driving ethical AI efforts found that the practice has a long way to go.</p>
          </div>
          <div class="resume-item">
            <h4>Venturebeat Women in AI Awards </h4>
            <h5>July 15, 2020</h5>
            <p>Nominated for the second annual Venturebeat <a href="https://venturebeat.com/2020/07/15/announcing-nominees-for-the-second-annual-women-in-ai-awards/">Women in AI Awards</a></p>
          </div>
          <div class="resume-item">
            <h4>Kaggle COVID-19 task winner</h4>
            <h5>April, 2020</h5>
            <p><a href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/discussion/148807">Kaggle competition winner</a> for my work on the CORD-19 research dataset which aims to <a href="https://www.kaggle.com/bobirakova/grammar-based-cord-19-approach">investigate the ethical and social science considerations regarding the COVID-19 pandemic outbreak response efforts.</a> See more about the findings in this <a href="https://www.linkedin.com/pulse/what-has-been-published-ethical-social-science-regarding-rakova/">blog post.</a></p>
          </div>
          <div class="resume-item">
            <h4>Startup co-founder in the intersection of AI and workforce automation</h4>
            <h5>2012 - 2014</h5>
            <p>Won multiple competitions with the company <a href="HG-Whitepaper.pdf">Hutgrip</a> where I was the technical co-founder. The startup was about helping small and medium sized manufacturing companies prevent failures on the production line by utilizing statistics and regression tools.  My role included identifying what are the problems in different manufacturing processes, analyzing if our software cloud-based tool can provide data insights to help solve them and measure the results. <a href="HG-Whitepaper.pdf">Read a white paper about the company here.</a></p>
          </div>
          <div class="resume-item">
            <h4>Samsung Research</h4>
            <h5>January, 2017</h5>
            <p>Featured as a Samsung Senior Research Engineer with my story about how <a href="https://news.samsung.com/us/Bogdana-Rakova-childhood-play-grows-ai-faces-of-samsung">Childhood play grows into AI</a></p>
          </div>
          <div class="resume-item">
            <h4>Amplify Partners </h4>
            <h5>2014</h5>
            <p>Connected Devices Fellow at Amplify Partners - an early-stage venture capital fund in Bay Area focused on Data Science.</p>
          </div>
          <div class="resume-item">
            <h4>Singularity University Global Impact Competition for Central and Eastern Europe</h4>
            <h5>2012</h5>
            <p>Recognized as one of the two finalists who received a scholarship of $25,000 for the Singularity University Graduate Studies Program in 2012.</p>
          </div>
          <div class="resume-item">
            <h4>Microsoft Imagine Cup Global Finals</h4>
            <h5>2011</h5>
            <p>Reached the global finals in the biggest Microsoft student technology competition with a game about environmental sustainability. The project qualified in the top five in the World in the Game Design category.</p>
          </div>


        </div>
      </div>

    </div>
  </section><!-- End Resume Section -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">

    </div>
  </footer><!-- End  Footer -->

  <div id="preloader"></div>
  <a href="#" target="_self" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
